---
title: "Apache Camel × AI ― サービングによる推論 #3: KServe"
emoji: "🐪"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["ai", "機械学習", "kubeflow", "camel", "mlops"]
published: false
---
![Camel AI](https://storage.googleapis.com/zenn-user-upload/2f89c845b33c-20250210.jpg =300x)

## KServeコンポーネント

## 準備



### モデルのステータスチェック

まず、モデルが推論可能な状態にあるかどうかを次のエンドポイントで確認できます。MNISTモデルのステータスを確認してみます。

```uri
tensorflow-serving:model-status?modelName=mnist&modelVersion=1
```

```java:model_status.java
//DEPS org.apache.camel:camel-bom:4.10.0@pom
//DEPS org.apache.camel:camel-core
//DEPS org.apache.camel:camel-tensorflow-serving

import org.apache.camel.builder.RouteBuilder;

public class model_status extends RouteBuilder {
    @Override
    public void configure() throws Exception {
        from("timer:model-status?repeatCount=1")
            .to("tensorflow-serving:model-status?modelName=mnist&modelVersion=1")
            .log("Status: ${body.getModelVersionStatus(0).state}");
    }
}
```

Camel CLIから以下のように実行します。

```console
camel run model_status.java
```

成功すれば、以下のようにMNISTモデルのステータスを確認できます。

```console
Status: AVAILABLE
```

## まとめ

TorchServeコンポーネントに引き続き、最新のCamel 4.10.0 LTSリリースで使えるAIモデルサービングコンポーネントの1つ、TensorFlow Servingコンポーネントの機能を一通り見てきました。

TensorFlow Servingコンポーネントを使えば、Camelをベースに構築したインテグレーションにTensorFlowで学習したAIモデルを簡単に取り入れられるようになります。TensorFlowベースの創造的なAIインテグレーションシステムの可能性が広がります。

次回は、最後にKServeコンポーネントを紹介します。

### サンプルコード

今回紹介したCamel×AIのサンプルコードは、このリポジトリで公開しています。

https://github.com/megacamelus/camel-ai-examples
